{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "scheduled-smoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "import argparse\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "HEIGHT = 32\n",
    "WIDTH = 32\n",
    "DEPTH = 3\n",
    "NUM_CLASSES = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "established-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_example_parser(serialized_example):\n",
    "    \"\"\"Parses a single tf.Example into image and label tensors.\"\"\"\n",
    "    # Dimensions of the images in the CIFAR-10 dataset.\n",
    "    # See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the\n",
    "    # input format.\n",
    "    features = tf.io.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'image': tf.io.FixedLenFeature([], tf.string),\n",
    "            'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "        })\n",
    "    image = tf.io.decode_raw(features['image'], tf.uint8)\n",
    "    image.set_shape([DEPTH * HEIGHT * WIDTH])\n",
    "\n",
    "    # Reshape from [depth * height * width] to [depth, height, width].\n",
    "    image = tf.cast(\n",
    "        tf.transpose(tf.reshape(image, [DEPTH, HEIGHT, WIDTH]), [1, 2, 0]),\n",
    "        tf.float32)\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "    \n",
    "    image = train_preprocess_fn(image)\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "agreed-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_preprocess_fn(image):\n",
    "\n",
    "    # Resize the image to add four extra pixels on each side.\n",
    "    image = tf.image.resize_with_crop_or_pad(image, HEIGHT + 8, WIDTH + 8)\n",
    "\n",
    "    # Randomly crop a [HEIGHT, WIDTH] section of the image.\n",
    "    image = tf.image.random_crop(image, [HEIGHT, WIDTH, DEPTH])\n",
    "\n",
    "    # Randomly flip the image horizontally.\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "seasonal-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(filenames, batch_size):\n",
    "    \"\"\"Read the images and labels from 'filenames'.\"\"\"\n",
    "    # Repeat infinitely.\n",
    "    dataset = tf.data.TFRecordDataset(filenames).repeat().shuffle(10000)\n",
    "\n",
    "    # Parse records.\n",
    "    dataset = dataset.map(single_example_parser, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    # Batch it up.\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ongoing-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape, learning_rate, weight_decay, optimizer, momentum):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    base_model = keras.applications.resnet50.ResNet50(include_top=False,\n",
    "                                                          weights='imagenet',\n",
    "                                                          input_tensor=input_tensor,\n",
    "                                                          input_shape=input_shape,\n",
    "                                                          classes=None)\n",
    "    x = Flatten()(base_model.output)\n",
    "    predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "federal-congress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 156 steps, validate for 39 steps\n",
      "Epoch 1/15\n",
      "156/156 [==============================] - 18s 114ms/step - loss: 1.3759 - accuracy: 0.5502 - val_loss: 1.7509 - val_accuracy: 0.5986\n",
      "Epoch 2/15\n",
      "156/156 [==============================] - 8s 53ms/step - loss: 0.9164 - accuracy: 0.6925 - val_loss: 1.0339 - val_accuracy: 0.6633\n",
      "Epoch 3/15\n",
      "156/156 [==============================] - 8s 53ms/step - loss: 0.8440 - accuracy: 0.7206 - val_loss: 2.0561 - val_accuracy: 0.4296\n",
      "Epoch 4/15\n",
      "156/156 [==============================] - 8s 52ms/step - loss: 1.0656 - accuracy: 0.6738 - val_loss: 2.2614 - val_accuracy: 0.4272\n",
      "Epoch 5/15\n",
      "156/156 [==============================] - 8s 52ms/step - loss: 0.9667 - accuracy: 0.6931 - val_loss: 0.9661 - val_accuracy: 0.6905\n",
      "Epoch 6/15\n",
      "156/156 [==============================] - 8s 52ms/step - loss: 0.9100 - accuracy: 0.7016 - val_loss: 5.8740 - val_accuracy: 0.5354\n",
      "Epoch 7/15\n",
      "156/156 [==============================] - 8s 52ms/step - loss: 0.8003 - accuracy: 0.7284 - val_loss: 1.5217 - val_accuracy: 0.6618\n",
      "Epoch 8/15\n",
      "156/156 [==============================] - 8s 52ms/step - loss: 0.9526 - accuracy: 0.6851 - val_loss: 1.7998 - val_accuracy: 0.5834\n",
      "Epoch 9/15\n",
      "156/156 [==============================] - 8s 52ms/step - loss: 0.7159 - accuracy: 0.7525 - val_loss: 0.8300 - val_accuracy: 0.7094\n",
      "Epoch 10/15\n",
      "156/156 [==============================] - 8s 52ms/step - loss: 0.6325 - accuracy: 0.7789 - val_loss: 0.7059 - val_accuracy: 0.7572\n",
      "Epoch 11/15\n",
      "156/156 [==============================] - 8s 52ms/step - loss: 0.6465 - accuracy: 0.7782 - val_loss: 0.8309 - val_accuracy: 0.7214\n",
      "Epoch 12/15\n",
      "156/156 [==============================] - 8s 53ms/step - loss: 1.1155 - accuracy: 0.6435 - val_loss: 2.3406 - val_accuracy: 0.3545\n",
      "Epoch 13/15\n",
      "156/156 [==============================] - 8s 53ms/step - loss: 0.8993 - accuracy: 0.7045 - val_loss: 1.4491 - val_accuracy: 0.5383\n",
      "Epoch 14/15\n",
      "156/156 [==============================] - 8s 53ms/step - loss: 0.8301 - accuracy: 0.7415 - val_loss: 1.3254 - val_accuracy: 0.6544\n",
      "Epoch 15/15\n",
      "156/156 [==============================] - 8s 52ms/step - loss: 0.6819 - accuracy: 0.7640 - val_loss: 0.7910 - val_accuracy: 0.7419\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.8375 - accuracy: 0.7331\n",
      "Test loss    : 0.8375098476043115\n",
      "Test accuracy: 0.73307294\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "epochs       = 15\n",
    "lr           = 0.001\n",
    "batch_size   = 256\n",
    "momentum     = 0.9\n",
    "weight_decay = 2e-4\n",
    "optimizer    = 'adam'\n",
    "model_type   = 'resnet'\n",
    "\n",
    "os.system('aws s3 sync s3://sagemaker-us-west-2-453691756499/datasets/cifar10-dataset/ dataset')\n",
    "\n",
    "training_dir   = 'dataset'\n",
    "validation_dir = 'dataset'\n",
    "eval_dir       = 'dataset'\n",
    "\n",
    "train_dataset = get_dataset(training_dir+'/train.tfrecords',  batch_size)\n",
    "val_dataset   = get_dataset(validation_dir+'/validation.tfrecords', batch_size)\n",
    "eval_dataset  = get_dataset(eval_dir+'/eval.tfrecords', batch_size)\n",
    "\n",
    "input_shape = (HEIGHT, WIDTH, DEPTH)\n",
    "model = get_model(input_shape, lr, weight_decay, optimizer, momentum)\n",
    "\n",
    "# Optimizer\n",
    "if optimizer.lower() == 'sgd':\n",
    "    opt = SGD(lr=lr, decay=weight_decay, momentum=momentum)\n",
    "else:\n",
    "    opt = Adam(lr=lr, decay=weight_decay)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(train_dataset, steps_per_epoch=40000 // batch_size,\n",
    "                    validation_data=val_dataset, \n",
    "                    validation_steps=10000 // batch_size,\n",
    "                    epochs=epochs)\n",
    "\n",
    "\n",
    "# Evaluate model performance\n",
    "score = model.evaluate(eval_dataset, steps=10000 // batch_size, verbose=1)\n",
    "print('Test loss    :', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-tiger",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
